---
title: Drone Detector App
emoji: ğŸš
colorFrom: indigo
colorTo: blue
sdk: gradio
sdk_version: "4.28.3"
app_file: app.py
pinned: false 
---

# ğŸ›¡ï¸ Real-Time Drone Intrusion Detection using YOLOv11m

> ğŸ¯ A deep learning-based object detection project for aerial intrusion surveillance, using YOLOv11m, trained on a custom drone dataset.

[![Ultralytics](https://img.shields.io/badge/YOLOv11m-Ultralytics-blue?logo=github)](https://github.com/ultralytics/ultralytics)
[![Colab GPU](https://img.shields.io/badge/Colab-Tesla%20T4-yellow?logo=googlecolab)](https://colab.research.google.com/)
[![Model Type](https://img.shields.io/badge/Model-YOLOv11m-brightgreen)](#)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“¸ Project Demo

> ğŸ”— **Live Demo Link**: [Click here](#https://huggingface.co/spaces/abinashp01/prototype-drone-detector-app-ab)
> ğŸ–¼ï¸ Sample Prediction:

<p align="center">
  <img src="demo_sample.jpg" alt="Sample Output" width="600">
</p>

---

## ğŸ§  Overview

This project is designed for **real-time drone detection** in aerial surveillance videos. It uses a custom-trained `YOLOv11m` model capable of detecting drones with high accuracy.

> âš ï¸ **Note**: While real-time performance is excellent on GPUs, CPU inference is slower. Recommendations below.

---

## ğŸ” Training Summary

| Detail            | Info                                                                                  |
| ----------------- | ------------------------------------------------------------------------------------- |
| **Model Used**    | `YOLOv11m` (medium-sized model)                                                       |
| **Training Time** | â±ï¸ First Training: 4.15 hours (40 epochs)<br>â±ï¸ Second Training: 8+ hours (80 epochs) |
| **Hardware Used** | âš¡ First: Google Colab GPU (Tesla T4)<br>âš¡ Second: Local NVIDIA RTX 3050 Laptop GPU    |
| **Model Size**    | ğŸ’¾ 40.5 MB                                                                            |
| **Final Weights** | `/models/2_best.pt`                                                                   |

---

## ğŸ—‚ï¸ Dataset Overview

### ğŸ“ Custom Dataset 1

* **Train**: 8378 images
* **Validation**: 1505 images
* **Test**: 65 images

### ğŸ“ Custom Dataset 2

* **Train**: 10359 images
* **Validation**: 2922 images
* **Test**: 1470 images

---

## ğŸ“Š Validation Performance (on Custom Dataset 1)

```text
Precision (P):      0.917 âœ…  
Recall (R):         0.876 âœ…  
mAP@0.5:            0.943 âœ…  
mAP@0.5:0.95:       0.661 âœ…  
```

---

## ğŸ§® Model Stats

| Metric     | Value  |
| ---------- | ------ |
| Parameters | 20.0 M |
| Layers     | 125    |
| GFLOPs     | 67.6   |

---

## ğŸ“ˆ Test Set Benchmarking Results

| Model      | Evaluated on     | mAP\@0.5   | mAP\@0.5:0.95 |
| ---------- | ---------------- | ---------- | ------------- |
| 1\_best.pt | Custom Dataset 1 | 0.8956     | 0.6850        |
| 2\_best.pt | Custom Dataset 1 | **0.9824** | **0.7389**    |
| 1\_best.pt | Custom Dataset 2 | 0.8171     | 0.3999        |
| 2\_best.pt | Custom Dataset 2 | **0.9573** | **0.6438**    |

---

## ğŸ† Final Model Recommendation

The **`2_best.pt`** model is the best performing across both datasets and is recommended for deployment or downstream tasks.

It was trained via **sequential fine-tuning**:

1. First on **Custom Dataset 1** (40 epochs, 4.15 hours)
2. Then fine-tuned further on **Custom Dataset 2** (80 epochs, 8+ hours)

This led to **significant improvements in generalization and detection accuracy**, achieving:

* **98.2% mAP\@0.5** on Dataset 1
* **95.7% mAP\@0.5** on Dataset 2
* With high mAP\@0.5:0.95 scores on both datasets.

---
## âš¡ Inference Speed

| Device          | Inference Time | FPS (approx) | Real-Time Capable |
| --------------- | -------------- | ------------ | ----------------- |
| **GPU (T4)**    | 11.2 ms/img    | \~75 FPS     | âœ… Yes             |
| **CPU (Colab)** | \~300 ms/img   | \~1â€“3 FPS    | âŒ No              |

```python
# YOLOv11m inference breakdown on GPU:
Preprocess:   0.3 ms
Inference:   11.2 ms
Postprocess:  1.4 ms
```

---

## ğŸ› ï¸ Inference Script (Sample)

```python
from ultralytics import YOLO

model = YOLO("models\yolov11m.pt")  # Path to trained model
results = model("sample.jpg", device="cpu")  # or "cuda:0"
results.show()
```

---

## ğŸ“ Directory Structure

```prototype-drone-detector-app-ab/
â”œâ”€â”€ .git/                          # Git version control
â”œâ”€â”€ artifacts/                     # Training artifacts and results
â”‚   â”œâ”€â”€ model_summary.txt
â”‚   â”œâ”€â”€ results_summary_exp1.txt
â”‚   â”œâ”€â”€ confusion_matrix_normalized.png
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ R_curve.png
â”‚   â”œâ”€â”€ P_curve.png
â”‚   â”œâ”€â”€ PR_curve.png
â”‚   â””â”€â”€ F1_curve.png
â”œâ”€â”€ core/                          # Core application modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ extract.py                 # Frame extraction functionality
â”‚   â”œâ”€â”€ predict.py                 # Object detection using YOLO
â”‚   â”œâ”€â”€ input_frames/              # Extracted video frames (auto-created)
â”‚   â”œâ”€â”€ output_frames/             # Detection results (auto-created)
â”‚   â””â”€â”€ __pycache__/               # Python cache files
â”œâ”€â”€ models/                        # YOLO model files
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ yolov11m.pt               # YOLOv11 medium model (39MB)
â”œâ”€â”€ notebook/                      # Jupyter notebooks
â”‚   â””â”€â”€ custom_model.ipynb        # Model training/development notebook
â”œâ”€â”€ app.py                        # Main Gradio web application
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ README.md                     # Project documentation
â”œâ”€â”€ .gitattributes               # Git configuration
â”œâ”€â”€ demo_sample.jpg              # Demo image sample
â””â”€â”€ sample.jpg                   # Sample image
```

## ğŸ“¦ Requirements

* Python â‰¥ 3.8
* PyTorch â‰¥ 2.0
* `ultralytics` (YOLOv8/11 compatible)

```bash
pip install ultralytics
```

---

## ğŸš€ Future Work

* [ ] Deploy `YOLOv11m` on webcam for real-time CPU inference
* [ ] Add a Gradio or Streamlit web demo
* [ ] Optimize for edge devices (Jetson, Raspberry Pi)

---

## ğŸ™‹â€â™‚ï¸ Author

**Abinash Pradhan**
ğŸš€ Aspiring Machine Learning Engineer | CV & Defense AI Projects
ğŸ“ Reach me: [LinkedIn](#https://www.linkedin.com/in/abinash-pradhan-a42157297/) | [Twitter](#https://x.com/abinashp01) | [Website](#https://abinashpradhan01.github.io/)

---

## ğŸ“„ License

This project is licensed under the APACHE 2.0 License - see the [LICENSE](LICENSE) file for details.

---
